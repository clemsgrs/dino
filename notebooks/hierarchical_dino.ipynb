{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82877ffa-cbc7-4c86-821c-755d4e7af662",
   "metadata": {},
   "source": [
    "# Hierarchical DINO Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea96aefd-07ef-4034-99fa-282f46a24720",
   "metadata": {},
   "source": [
    "generic imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d51f04-2d7a-4643-a12c-2dce1539d925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import wandb\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "import hydra\n",
    "import shutil\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import multiprocessing as mp\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633b4091-eda0-46a8-a0a1-644196b42fd2",
   "metadata": {},
   "source": [
    "module imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2646fed2-a2b9-4187-b09b-8947c76ff87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.append(\"/path/to/dino\")\n",
    "sys.path.append(\"/home/clementgrisi/clement/code/dino\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8bdb74-a95a-42a0-8518-827375fd0fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dino.models.vision_transformer as vits\n",
    "\n",
    "from dino.components import DINOLoss\n",
    "from dino.data import RegionDataAugmentationDINO, HierarchicalPretrainingDataset\n",
    "from dino.models import MultiCropWrapper\n",
    "from dino.distributed import get_world_size, is_main_process\n",
    "from dino.utils import (\n",
    "train_one_epoch,\n",
    "cosine_scheduler,\n",
    "fix_random_seeds,\n",
    "has_batchnorms,\n",
    "get_params_groups,\n",
    "compute_time,\n",
    "start_from_checkpoint,\n",
    "resume_from_checkpoint,\n",
    ")\n",
    "from dino.utils.utils import clip_gradients, cancel_gradients_last_layer\n",
    "from dino.log import initialize_wandb, update_log_dict, MetricLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1c0986-3ac2-4c43-9649-b47ced52671c",
   "metadata": {},
   "source": [
    "load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1c358e-889e-4158-b521-41495d0badfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"/home/clementgrisi/clement/code/dino/dino/config/region_debug.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fa6267-723c-48e1-8df3-8107ce0568ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load(config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bfce43-f922-485c-9343-a84d94d8dd2c",
   "metadata": {},
   "source": [
    "initialize distributed session (if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8428a4fb-9b1a-4a73-bd25-e2c26f2e49e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "distributed = torch.cuda.device_count() > 1\n",
    "if distributed:\n",
    "    torch.distributed.init_process_group(backend=\"nccl\")\n",
    "    gpu_id = int(os.environ[\"LOCAL_RANK\"])\n",
    "    if gpu_id == 0:\n",
    "        print(\"Distributed session successfully initialized\")\n",
    "else:\n",
    "    gpu_id = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee1adee-b7c2-418d-82b9-0981cd018c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_main_process():\n",
    "    print(f\"torch.cuda.device_count(): {torch.cuda.device_count()}\")\n",
    "    run_id = datetime.datetime.now().strftime(\"%Y-%m-%d_%H_%M\")\n",
    "    # set up wandb\n",
    "    if cfg.wandb.enable:\n",
    "        key = os.environ.get(\"WANDB_API_KEY\")\n",
    "        wandb_run = initialize_wandb(cfg, key=key)\n",
    "        wandb_run.define_metric(\"epoch\", summary=\"max\")\n",
    "        run_id = wandb_run.id\n",
    "else:\n",
    "    run_id = \"\"\n",
    "\n",
    "if distributed:\n",
    "    obj = [run_id]\n",
    "    torch.distributed.broadcast_object_list(\n",
    "        obj, 0, device=torch.device(f\"cuda:{gpu_id}\")\n",
    "    )\n",
    "    run_id = obj[0]\n",
    "\n",
    "fix_random_seeds(cfg.seed)\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce4f793-6ae0-4ad1-9add-c6b7dccaf0bf",
   "metadata": {},
   "source": [
    "create output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47226a95-7aaa-41c9-a390-e5a85545a6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef3047f-f42b-491c-809b-f0ad39419764",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(cfg.output_dir, cfg.experiment_name, run_id)\n",
    "snapshot_dir = Path(output_dir, \"snapshots\")\n",
    "if not cfg.resume and is_main_process():\n",
    "    if output_dir.exists():\n",
    "        print(f\"WARNING: {output_dir} already exists! Deleting its content...\")\n",
    "        shutil.rmtree(output_dir)\n",
    "        output_dir.mkdir(parents=True)\n",
    "    else:\n",
    "        output_dir.mkdir(exist_ok=True, parents=True)\n",
    "    snapshot_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e415d8d-703f-490b-b00f-23b5c35cf564",
   "metadata": {},
   "source": [
    "prepare pretraining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641811cb-2071-4090-976e-299173e251d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = RegionDataAugmentationDINO(\n",
    "    cfg.aug.global_crops_scale,\n",
    "    cfg.aug.local_crops_number,\n",
    "    cfg.aug.local_crops_scale,\n",
    "    cfg.model.region_size,\n",
    "    cfg.model.patch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0519bfa-bcb7-4f9b-b1fb-0640e6cd466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using custom dataset for our [256 x 384] tensors (\"local\" features)\n",
    "dataset = HierarchicalPretrainingDataset(cfg.data_dir, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ccbdf2-97fd-444d-8a12-e66cfe5f8b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.training.pct:\n",
    "    print(f\"Pre-training on {cfg.training.pct*100}% of the data\")\n",
    "    nsample = int(cfg.training.pct * len(dataset))\n",
    "    idxs = random.sample(range(len(dataset)), k=nsample)\n",
    "    dataset = torch.utils.data.Subset(dataset, idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31a94ae-2a96-4b1b-8b18-0b3851480642",
   "metadata": {},
   "outputs": [],
   "source": [
    "if distributed:\n",
    "    sampler = torch.utils.data.DistributedSampler(dataset, shuffle=True)\n",
    "else:\n",
    "    sampler = torch.utils.data.RandomSampler(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085cfaaf-6ed7-4619-ab66-11c30daba50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = min(mp.cpu_count(), cfg.speed.num_workers)\n",
    "if \"SLURM_JOB_CPUS_PER_NODE\" in os.environ:\n",
    "    num_workers = min(num_workers, int(os.environ[\"SLURM_JOB_CPUS_PER_NODE\"]))\n",
    "num_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29a2389-9904-44e2-9d15-045984fb57ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    sampler=sampler,\n",
    "    batch_size=cfg.training.batch_size_per_gpu,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "print(f\"Pretraining data loaded ({len(dataset)} regions)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90230f5f-5e2a-45f1-92af-f8e9e9a72c01",
   "metadata": {},
   "source": [
    "build student and teacher networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e9fb94-de94-4906-8ae7-76aa7d3985f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "student = vits.__dict__[cfg.model.arch](\n",
    "    img_size=cfg.model.region_size,\n",
    "    patch_size=cfg.model.patch_size,\n",
    "    drop_path_rate=cfg.model.drop_path_rate,\n",
    ")\n",
    "teacher = vits.__dict__[cfg.model.arch](\n",
    "    img_size=cfg.model.region_size, patch_size=cfg.model.patch_size\n",
    ")\n",
    "embed_dim = student.embed_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6640406b-2c48-49e7-b83a-af97ce666ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-crop wrapper handles forward with inputs of different resolutions\n",
    "student = MultiCropWrapper(\n",
    "    student,\n",
    "    vits.DINOHead(\n",
    "        embed_dim,\n",
    "        cfg.model.out_dim,\n",
    "        use_bn=cfg.model.use_bn_in_head,\n",
    "        norm_last_layer=cfg.model.norm_last_layer,\n",
    "    ),\n",
    ")\n",
    "teacher = MultiCropWrapper(\n",
    "    teacher,\n",
    "    vits.DINOHead(\n",
    "        embed_dim,\n",
    "        cfg.model.out_dim,\n",
    "        use_bn=cfg.model.use_bn_in_head,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da05c6dc-a063-4dd1-801e-05ef686aed3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move networks to gpu\n",
    "if distributed:\n",
    "    student, teacher = student.to(gpu_id), teacher.to(gpu_id)\n",
    "else:\n",
    "    student, teacher = student.cuda(), teacher.cuda()\n",
    "\n",
    "# synchronize batch norms (if any)\n",
    "if has_batchnorms(student) and distributed:\n",
    "    # we need DDP wrapper to have synchro batch norms working...\n",
    "    student = nn.SyncBatchNorm.convert_sync_batchnorm(student)\n",
    "    teacher = nn.SyncBatchNorm.convert_sync_batchnorm(teacher)\n",
    "    teacher = nn.parallel.DistributedDataParallel(\n",
    "        teacher, device_ids=[gpu_id], output_device=gpu_id\n",
    "    )\n",
    "    teacher_without_ddp = teacher.module\n",
    "else:\n",
    "    # teacher_without_ddp and teacher are the same thing\n",
    "    teacher_without_ddp = teacher\n",
    "\n",
    "if distributed:\n",
    "    student = nn.parallel.DistributedDataParallel(\n",
    "        student,\n",
    "        device_ids=[gpu_id],\n",
    "        output_device=gpu_id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3539d79c-e740-4e10-a8b8-581001de6e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally start student from existing checkpoint\n",
    "if cfg.start_from_checkpoint:\n",
    "    ckpt_path = Path(cfg.start_from_checkpoint)\n",
    "    start_from_checkpoint(\n",
    "        ckpt_path,\n",
    "        student,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acfe91f-a8fd-408a-9a6e-ca58e96647f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# teacher and student start with the same weights\n",
    "student_sd = student.state_dict()\n",
    "nn.modules.utils.consume_prefix_in_state_dict_if_present(student_sd, \"module.\")\n",
    "teacher_without_ddp.load_state_dict(student_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f1ef1-4d11-49db-92bd-dc01f9f6b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is no backpropagation through the teacher, so no need for gradients\n",
    "for p in teacher.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcaeea4-3ebf-4507-a01e-d898092c8f26",
   "metadata": {},
   "source": [
    "create loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f885da4-1d9a-447a-9c7e-57060146c36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of crops = 2 global crops + local_crops_number\n",
    "crops_number = cfg.aug.local_crops_number + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e97d4cd-b0a5-4780-bde6-22c9ae491e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "dino_loss = DINOLoss(\n",
    "    cfg.model.out_dim,\n",
    "    crops_number,\n",
    "    cfg.model.warmup_teacher_temp,\n",
    "    cfg.model.teacher_temp,\n",
    "    cfg.model.warmup_teacher_temp_epochs,\n",
    "    cfg.training.nepochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764ade05-b5c6-4229-a28a-9d00575961c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if distributed:\n",
    "    dino_loss = dino_loss.to(gpu_id)\n",
    "else:\n",
    "    dino_loss = dino_loss.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86e7610-e9cb-4613-8576-d574cfc028de",
   "metadata": {},
   "source": [
    "create optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e80c7e0-d693-49f5-8470-c0eb79ff6a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_groups = get_params_groups(student)\n",
    "optimizer = torch.optim.AdamW(params_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21e8570-ea69-413c-9dd9-176de63adba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mixed precision training\n",
    "fp16_scaler = None\n",
    "if cfg.speed.use_fp16:\n",
    "    fp16_scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059f2381-3712-4fbe-81e0-b1d4df9d1eae",
   "metadata": {},
   "source": [
    "create schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1132e27-0909-4825-8491-bb9fe16d7501",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    cfg.training.nepochs >= cfg.training.warmup_epochs\n",
    "), f\"nepochs ({cfg.training.nepochs}) must be greater than or equal to warmup_epochs ({cfg.training.warmup_epochs})\"\n",
    "base_lr = (\n",
    "    cfg.optim.lr * (cfg.training.batch_size_per_gpu * get_world_size()) / 256.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a685d0f0-e6ad-4828-9eca-761f90858dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = cosine_scheduler(\n",
    "    base_lr,\n",
    "    cfg.optim.lr_scheduler.min_lr,\n",
    "    cfg.training.nepochs,\n",
    "    len(data_loader),\n",
    "    warmup_epochs=cfg.training.warmup_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf1b000-31df-423d-a68f-de8396c0d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_schedule = cosine_scheduler(\n",
    "    cfg.optim.lr_scheduler.weight_decay,\n",
    "    cfg.optim.lr_scheduler.weight_decay_end,\n",
    "    cfg.training.nepochs,\n",
    "    len(data_loader),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b24c197-0de8-47f3-b661-dafe63b7314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# momentum parameter is increased to 1. during training with a cosine schedule\n",
    "momentum_schedule = cosine_scheduler(\n",
    "    cfg.model.momentum_teacher,\n",
    "    1,\n",
    "    cfg.training.nepochs,\n",
    "    len(data_loader),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62ed267-608c-4eac-b46e-a5b1fd559435",
   "metadata": {},
   "source": [
    "pretrain utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf13ae8-b14f-4e2c-9dcc-7d32c3263fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    student,\n",
    "    teacher,\n",
    "    teacher_without_ddp,\n",
    "    dino_loss,\n",
    "    data_loader,\n",
    "    optimizer,\n",
    "    lr_schedule,\n",
    "    wd_schedule,\n",
    "    momentum_schedule,\n",
    "    epoch,\n",
    "    nepochs,\n",
    "    fp16_scaler,\n",
    "    clip_grad,\n",
    "    freeze_last_layer,\n",
    "    gpu_id,\n",
    "):\n",
    "    metric_logger = MetricLogger(delimiter=\"  \")\n",
    "    with tqdm(\n",
    "        data_loader,\n",
    "        desc=(f\"Epoch [{epoch+1}/{nepochs}]\"),\n",
    "        unit=\" img\",\n",
    "        ncols=80,\n",
    "        unit_scale=data_loader.batch_size,\n",
    "        leave=False,\n",
    "        disable=not (gpu_id in [-1, 0]),\n",
    "    ) as t:\n",
    "        for it, (images, _) in enumerate(t):\n",
    "            # update weight decay and learning rate according to their schedule\n",
    "            it = len(data_loader) * epoch + it  # global training iteration\n",
    "            for i, param_group in enumerate(optimizer.param_groups):\n",
    "                param_group[\"lr\"] = lr_schedule[it]\n",
    "                if i == 0:  # only the first group is regularized\n",
    "                    param_group[\"weight_decay\"] = wd_schedule[it]\n",
    "\n",
    "            # move images to gpu\n",
    "            if gpu_id == -1:\n",
    "                images = [im.cuda(non_blocking=True) for im in images]\n",
    "            else:\n",
    "                device = torch.device(f\"cuda:{gpu_id}\")\n",
    "                images = [im.to(device, non_blocking=True) for im in images]\n",
    "            # teacher and student forward passes + compute dino loss\n",
    "            with torch.cuda.amp.autocast(fp16_scaler is not None):\n",
    "                teacher_output = teacher(\n",
    "                    images[:2]\n",
    "                )  # only the 2 global views pass through the teacher\n",
    "                student_output = student(images)\n",
    "                loss = dino_loss(student_output, teacher_output, epoch)\n",
    "\n",
    "            if not math.isfinite(loss.item()):\n",
    "                tqdm.write(\n",
    "                    \"Loss is {}, stopping training\".format(loss.item()), force=True\n",
    "                )\n",
    "                sys.exit(1)\n",
    "\n",
    "            # student update\n",
    "            optimizer.zero_grad()\n",
    "            param_norms = None\n",
    "            if fp16_scaler is None:\n",
    "                loss.backward()\n",
    "                if clip_grad:\n",
    "                    param_norms = clip_gradients(student, clip_grad)\n",
    "                cancel_gradients_last_layer(epoch, student, freeze_last_layer)\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                fp16_scaler.scale(loss).backward()\n",
    "                if clip_grad:\n",
    "                    fp16_scaler.unscale_(\n",
    "                        optimizer\n",
    "                    )  # unscale the gradients of optimizer's assigned params in-place\n",
    "                    param_norms = clip_gradients(student, clip_grad)\n",
    "                cancel_gradients_last_layer(epoch, student, freeze_last_layer)\n",
    "                fp16_scaler.step(optimizer)\n",
    "                fp16_scaler.update()\n",
    "\n",
    "            # EMA update for the teacher\n",
    "            with torch.no_grad():\n",
    "                m = momentum_schedule[it]  # momentum parameter\n",
    "                if torch.cuda.device_count() > 1:\n",
    "                    student_params = student.module.parameters()\n",
    "                else:\n",
    "                    student_params = student.parameters()\n",
    "                for param_q, param_k in zip(\n",
    "                    student_params, teacher_without_ddp.parameters()\n",
    "                ):\n",
    "                    param_k.data.mul_(m).add_((1 - m) * param_q.detach().data)\n",
    "\n",
    "            # logging\n",
    "            torch.cuda.synchronize()\n",
    "            metric_logger.update(loss=loss.item())\n",
    "            metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
    "            metric_logger.update(wd=optimizer.param_groups[0][\"weight_decay\"])\n",
    "\n",
    "    # gather the stats from all processes\n",
    "    metric_logger.synchronize_between_processes(gpu_id)\n",
    "    # print(\"Averaged stats:\", metric_logger)\n",
    "    train_stats = {k: meter.global_avg for k, meter in metric_logger.meters.items()}\n",
    "    return train_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25c678a-3ebe-4e4e-a1a9-a0ed9494d5d2",
   "metadata": {},
   "source": [
    "pretrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d19b46e-3c35-4c37-98ff-5f39a7cba18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_run = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs_run, cfg.training.nepochs):\n",
    "    epoch_start_time = time.time()\n",
    "    if cfg.wandb.enable and is_main_process():\n",
    "        log_dict = {\"epoch\": epoch}\n",
    "\n",
    "    if distributed:\n",
    "        data_loader.sampler.set_epoch(epoch)\n",
    "\n",
    "    # training one epoch of DINO\n",
    "    train_stats = train_one_epoch(\n",
    "        student,\n",
    "        teacher,\n",
    "        teacher_without_ddp,\n",
    "        dino_loss,\n",
    "        data_loader,\n",
    "        optimizer,\n",
    "        lr_schedule,\n",
    "        wd_schedule,\n",
    "        momentum_schedule,\n",
    "        epoch,\n",
    "        cfg.training.nepochs,\n",
    "        fp16_scaler,\n",
    "        cfg.training.clip_grad,\n",
    "        cfg.training.freeze_last_layer,\n",
    "        gpu_id,\n",
    "    )\n",
    "\n",
    "    if cfg.wandb.enable and is_main_process():\n",
    "        update_log_dict(\"train\", train_stats, log_dict, step=\"epoch\")\n",
    "\n",
    "    # save snapshot and log to wandb\n",
    "    if is_main_process():\n",
    "        snapshot = {\n",
    "            \"epoch\": epoch,\n",
    "            \"student\": student.state_dict(),\n",
    "            \"teacher\": teacher.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"dino_loss\": dino_loss.state_dict(),\n",
    "        }\n",
    "        if fp16_scaler is not None:\n",
    "            snapshot[\"fp16_scaler\"] = fp16_scaler.state_dict()\n",
    "\n",
    "        save_path = Path(snapshot_dir, f\"epoch_{epoch:03}.pt\")\n",
    "        if (\n",
    "            cfg.logging.save_snapshot_every\n",
    "            and epoch % cfg.logging.save_snapshot_every == 0\n",
    "        ):\n",
    "            torch.save(snapshot, save_path)\n",
    "        torch.save(snapshot, Path(snapshot_dir, \"latest.pt\"))\n",
    "\n",
    "        if cfg.wandb.enable:\n",
    "            wandb.log(log_dict, step=epoch)\n",
    "\n",
    "    log_stats = {\n",
    "        **{f\"train_{k}\": v for k, v in train_stats.items()},\n",
    "        \"epoch\": epoch,\n",
    "    }\n",
    "    if is_main_process():\n",
    "        with open(Path(output_dir, \"log.txt\"), \"a\") as f:\n",
    "            f.write(json.dumps(log_stats) + \"\\n\")\n",
    "\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_mins, epoch_secs = compute_time(epoch_start_time, epoch_end_time)\n",
    "    if is_main_process():\n",
    "        tqdm.write(\n",
    "            f\"End of epoch {epoch+1}/{cfg.training.nepochs} \\t Time Taken:  {epoch_mins}m {epoch_secs}s\"\n",
    "        )\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "print(\"Pretraining time {}\".format(total_time_str))\n",
    "\n",
    "if distributed:\n",
    "    torch.distributed.destroy_process_group()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
