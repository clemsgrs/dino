{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82877ffa-cbc7-4c86-821c-755d4e7af662",
   "metadata": {},
   "source": [
    "# Vanilla DINO Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea96aefd-07ef-4034-99fa-282f46a24720",
   "metadata": {},
   "source": [
    "generic imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d51f04-2d7a-4643-a12c-2dce1539d925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import hydra\n",
    "import wandb\n",
    "import shutil\n",
    "import random\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "from torchvision import datasets\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633b4091-eda0-46a8-a0a1-644196b42fd2",
   "metadata": {},
   "source": [
    "module imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2646fed2-a2b9-4187-b09b-8947c76ff87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/path/to/your/dino/folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8bdb74-a95a-42a0-8518-827375fd0fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dino.models.vision_transformer as vits\n",
    "\n",
    "from dino.components import DINOLoss, EarlyStoppingDINO\n",
    "from dino.data import PatchDataAugmentationDINO\n",
    "from dino.eval import prepare_data\n",
    "from dino.models import MultiCropWrapper\n",
    "from dino.distributed import get_world_size, is_main_process\n",
    "from dino.utils import cosine_scheduler, fix_random_seeds, has_batchnorms, get_params_groups, compute_time, resume_from_checkpoint\n",
    "from dino.log import initialize_wandb, update_log_dict, MetricLogger\n",
    "from dino.eval.knn import knn_classifier\n",
    "from dino.utils.utils import load_weights, clip_gradients, cancel_gradients_last_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1c0986-3ac2-4c43-9649-b47ced52671c",
   "metadata": {},
   "source": [
    "load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1c358e-889e-4158-b521-41495d0badfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"/path/to/your/patch/config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fa6267-723c-48e1-8df3-8107ce0568ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load(config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bfce43-f922-485c-9343-a84d94d8dd2c",
   "metadata": {},
   "source": [
    "initialize distributed session (if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56af123-71d2-406f-a421-a57f0024231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "distributed = torch.cuda.device_count() > 1\n",
    "if distributed:\n",
    "    torch.distributed.init_process_group(backend=\"nccl\")\n",
    "    gpu_id = int(os.environ[\"LOCAL_RANK\"])\n",
    "    if gpu_id == 0:\n",
    "        print(f\"Distributed session successfully initialized\")\n",
    "else:\n",
    "    gpu_id = -1\n",
    "\n",
    "if is_main_process():\n",
    "    print(f\"torch.cuda.device_count(): {torch.cuda.device_count()}\")\n",
    "    run_id = datetime.datetime.now().strftime(\"%Y-%m-%d_%H_%M\")\n",
    "    # set up wandb\n",
    "    if cfg.wandb.enable:\n",
    "        key = os.environ.get(\"WANDB_API_KEY\")\n",
    "        wandb_run = initialize_wandb(cfg, key=key)\n",
    "        wandb_run.define_metric(\"epoch\", summary=\"max\")\n",
    "        run_id = wandb_run.id\n",
    "else:\n",
    "    run_id = \"\"\n",
    "\n",
    "if distributed:\n",
    "    obj = [run_id]\n",
    "    torch.distributed.broadcast_object_list(\n",
    "        obj, 0, device=torch.device(f\"cuda:{gpu_id}\")\n",
    "    )\n",
    "    run_id = obj[0]\n",
    "\n",
    "fix_random_seeds(cfg.seed)\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce4f793-6ae0-4ad1-9add-c6b7dccaf0bf",
   "metadata": {},
   "source": [
    "create output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47226a95-7aaa-41c9-a390-e5a85545a6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13dbf85-482a-46fc-9d3a-4e7fc2899953",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(cfg.output_dir, cfg.experiment_name, run_id)\n",
    "snapshot_dir = Path(output_dir, \"snapshots\")\n",
    "features_dir = Path(output_dir, \"features\")\n",
    "if not cfg.resume and is_main_process():\n",
    "    if output_dir.exists():\n",
    "        print(f\"WARNING: {output_dir} already exists! Deleting its content...\")\n",
    "        shutil.rmtree(output_dir)\n",
    "        output_dir.mkdir(parents=True)\n",
    "    else:\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    snapshot_dir.mkdir(exist_ok=True, parents=True)\n",
    "    if cfg.early_stopping.tune_every and cfg.early_stopping.knn.save_features:\n",
    "        features_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3645de-1da3-4713-b6ab-584fc02d2402",
   "metadata": {},
   "source": [
    "prepare downstream tuning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687b4a40-503d-4fdd-bbc0-43d6f649a618",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_main_process() and cfg.early_stopping.tune_every:\n",
    "\n",
    "    # only do it from master rank as tuning is not being run distributed for now\n",
    "    train_df = pd.read_csv(cfg.early_stopping.downstream.train_csv)\n",
    "    test_df = pd.read_csv(cfg.early_stopping.downstream.test_csv)\n",
    "\n",
    "    num_workers = min(mp.cpu_count(), cfg.early_stopping.downstream.num_workers)\n",
    "    if \"SLURM_JOB_CPUS_PER_NODE\" in os.environ:\n",
    "        num_workers = min(num_workers, int(os.environ[\"SLURM_JOB_CPUS_PER_NODE\"]))\n",
    "\n",
    "    downstream_train_loader, downstream_test_loader = prepare_data(\n",
    "        train_df,\n",
    "        test_df,\n",
    "        cfg.early_stopping.downstream.batch_size_per_gpu,\n",
    "        False,\n",
    "        num_workers,\n",
    "        cfg.early_stopping.downstream.label_name,\n",
    "    )\n",
    "    print(\n",
    "        f\"Tuning data loaded with {len(downstream_train_loader.dataset)} train patches and {len(downstream_test_loader.dataset)} test patches.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e415d8d-703f-490b-b00f-23b5c35cf564",
   "metadata": {},
   "source": [
    "prepare pretraining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641811cb-2071-4090-976e-299173e251d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = PatchDataAugmentationDINO(\n",
    "    cfg.aug.global_crops_scale,\n",
    "    cfg.aug.local_crops_scale,\n",
    "    cfg.aug.local_crops_number,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0519bfa-bcb7-4f9b-b1fb-0640e6cd466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_loading_start_time = time.time()\n",
    "dataset = datasets.ImageFolder(cfg.data_dir, transform=transform)\n",
    "dataset_loading_end_time = time.time() - dataset_loading_start_time\n",
    "total_time_str = str(datetime.timedelta(seconds=int(dataset_loading_end_time)))\n",
    "if is_main_process():\n",
    "    print(f\"Pretraining data loaded in {total_time_str} ({len(dataset)} patches)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ccbdf2-97fd-444d-8a12-e66cfe5f8b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.training.pct:\n",
    "    print(f\"Pre-training on {cfg.training.pct*100}% of the data\")\n",
    "    nsample = int(cfg.training.pct * len(dataset))\n",
    "    idxs = random.sample(range(len(dataset)), k=nsample)\n",
    "    dataset = torch.utils.data.Subset(dataset, idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31a94ae-2a96-4b1b-8b18-0b3851480642",
   "metadata": {},
   "outputs": [],
   "source": [
    "if distributed:\n",
    "    sampler = torch.utils.data.DistributedSampler(dataset, shuffle=True)\n",
    "else:\n",
    "    sampler = torch.utils.data.RandomSampler(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085cfaaf-6ed7-4619-ab66-11c30daba50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = min(mp.cpu_count(), cfg.speed.num_workers)\n",
    "if \"SLURM_JOB_CPUS_PER_NODE\" in os.environ:\n",
    "    num_workers = min(num_workers, int(os.environ[\"SLURM_JOB_CPUS_PER_NODE\"]))\n",
    "num_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29a2389-9904-44e2-9d15-045984fb57ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    sampler=sampler,\n",
    "    batch_size=cfg.training.batch_size_per_gpu,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90230f5f-5e2a-45f1-92af-f8e9e9a72c01",
   "metadata": {},
   "source": [
    "build student and teacher networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e9fb94-de94-4906-8ae7-76aa7d3985f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "student = vits.__dict__[cfg.model.arch](\n",
    "    patch_size=cfg.model.patch_size,\n",
    "    drop_path_rate=cfg.model.drop_path_rate,\n",
    ")\n",
    "teacher = vits.__dict__[cfg.model.arch](patch_size=cfg.model.patch_size)\n",
    "embed_dim = student.embed_dim\n",
    "embed_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ce35e5-b9cd-4bbf-a48c-d15381451973",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher.embed_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d8ec4b-2be9-488f-a757-059d708ef1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.model.out_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6640406b-2c48-49e7-b83a-af97ce666ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-crop wrapper handles forward with inputs of different resolutions\n",
    "student = MultiCropWrapper(\n",
    "    student,\n",
    "    vits.DINOHead(\n",
    "        embed_dim,\n",
    "        cfg.model.out_dim,\n",
    "        use_bn=cfg.model.use_bn_in_head,\n",
    "        norm_last_layer=cfg.model.norm_last_layer,\n",
    "    ),\n",
    ")\n",
    "teacher = MultiCropWrapper(\n",
    "    teacher,\n",
    "    vits.DINOHead(\n",
    "        embed_dim,\n",
    "        cfg.model.out_dim,\n",
    "        use_bn=cfg.model.use_bn_in_head,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da05c6dc-a063-4dd1-801e-05ef686aed3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move networks to gpu\n",
    "if distributed:\n",
    "    student, teacher = student.to(gpu_id), teacher.to(gpu_id)\n",
    "else:\n",
    "    student, teacher = student.cuda(), teacher.cuda()\n",
    "\n",
    "# synchronize batch norms (if any)\n",
    "if has_batchnorms(student) and distributed:\n",
    "    # we need DDP wrapper to have synchro batch norms working...\n",
    "    student = nn.SyncBatchNorm.convert_sync_batchnorm(student)\n",
    "    teacher = nn.SyncBatchNorm.convert_sync_batchnorm(teacher)\n",
    "    teacher = nn.parallel.DistributedDataParallel(\n",
    "        teacher, device_ids=[gpu_id], output_device=gpu_id\n",
    "    )\n",
    "    teacher_without_ddp = teacher.module\n",
    "else:\n",
    "    # teacher_without_ddp and teacher are the same thing\n",
    "    teacher_without_ddp = teacher\n",
    "\n",
    "if distributed:\n",
    "    student = nn.parallel.DistributedDataParallel(\n",
    "        student, device_ids=[gpu_id], output_device=gpu_id\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acfe91f-a8fd-408a-9a6e-ca58e96647f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# teacher and student start with the same weights\n",
    "student_sd = student.state_dict()\n",
    "nn.modules.utils.consume_prefix_in_state_dict_if_present(student_sd, \"module.\")\n",
    "teacher_without_ddp.load_state_dict(student_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f1ef1-4d11-49db-92bd-dc01f9f6b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is no backpropagation through the teacher, so no need for gradients\n",
    "for p in teacher.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcaeea4-3ebf-4507-a01e-d898092c8f26",
   "metadata": {},
   "source": [
    "create loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f885da4-1d9a-447a-9c7e-57060146c36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of crops = 2 global crops + local_crops_number\n",
    "crops_number = cfg.aug.local_crops_number + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e97d4cd-b0a5-4780-bde6-22c9ae491e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "dino_loss = DINOLoss(\n",
    "    cfg.model.out_dim,\n",
    "    crops_number,\n",
    "    cfg.model.warmup_teacher_temp,\n",
    "    cfg.model.teacher_temp,\n",
    "    cfg.model.warmup_teacher_temp_epochs,\n",
    "    cfg.training.nepochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764ade05-b5c6-4229-a28a-9d00575961c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if distributed:\n",
    "    dino_loss = dino_loss.to(gpu_id)\n",
    "else:\n",
    "    dino_loss = dino_loss.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86e7610-e9cb-4613-8576-d574cfc028de",
   "metadata": {},
   "source": [
    "create optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e80c7e0-d693-49f5-8470-c0eb79ff6a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_groups = get_params_groups(student)\n",
    "optimizer = torch.optim.AdamW(params_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21e8570-ea69-413c-9dd9-176de63adba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mixed precision training\n",
    "fp16_scaler = None\n",
    "if cfg.speed.use_fp16:\n",
    "    fp16_scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059f2381-3712-4fbe-81e0-b1d4df9d1eae",
   "metadata": {},
   "source": [
    "create schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1132e27-0909-4825-8491-bb9fe16d7501",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    cfg.training.nepochs >= cfg.training.warmup_epochs\n",
    "), f\"nepochs ({cfg.training.nepochs}) must be greater than or equal to warmup_epochs ({cfg.training.warmup_epochs})\"\n",
    "base_lr = (\n",
    "    cfg.optim.lr * (cfg.training.batch_size_per_gpu * get_world_size()) / 256.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a685d0f0-e6ad-4828-9eca-761f90858dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = cosine_scheduler(\n",
    "    base_lr,\n",
    "    cfg.optim.lr_scheduler.min_lr,\n",
    "    cfg.training.nepochs,\n",
    "    len(data_loader),\n",
    "    warmup_epochs=cfg.training.warmup_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf1b000-31df-423d-a68f-de8396c0d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_schedule = cosine_scheduler(\n",
    "    cfg.optim.lr_scheduler.weight_decay,\n",
    "    cfg.optim.lr_scheduler.weight_decay_end,\n",
    "    cfg.training.nepochs,\n",
    "    len(data_loader),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b24c197-0de8-47f3-b661-dafe63b7314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# momentum parameter is increased to 1. during training with a cosine schedule\n",
    "momentum_schedule = cosine_scheduler(\n",
    "    cfg.model.momentum_teacher, 1, cfg.training.nepochs, len(data_loader)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acac710c-b05c-4671-830f-03c51bd9a847",
   "metadata": {},
   "source": [
    "create early stopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b3dbf3-014a-4f22-8c03-7f330ab51c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.early_stopping.tune_every:\n",
    "    early_stopping = EarlyStoppingDINO(\n",
    "        cfg.early_stopping.tracking,\n",
    "        cfg.early_stopping.min_max,\n",
    "        cfg.early_stopping.patience,\n",
    "        cfg.early_stopping.min_epoch,\n",
    "        checkpoint_dir=snapshot_dir,\n",
    "        save_every=cfg.early_stopping.save_every,\n",
    "        verbose=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a27a99-65fb-4bc5-a915-240582fd711b",
   "metadata": {},
   "source": [
    "tune utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e027203a-e1d0-44f1-ad57-8a33f4499b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def extract_multiple_features(\n",
    "    student,\n",
    "    teacher,\n",
    "    loader,\n",
    "    distributed,\n",
    "    use_cuda=True,\n",
    "    multiscale=False,\n",
    "):\n",
    "    student_features = None\n",
    "    teacher_features = None\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    with tqdm(\n",
    "        loader,\n",
    "        desc=(f\"Feature extraction\"),\n",
    "        unit=\" slide\",\n",
    "        ncols=80,\n",
    "        unit_scale=loader.batch_size,\n",
    "        leave=True,\n",
    "    ) as t:\n",
    "        for i, batch in enumerate(t):\n",
    "            index, img, label = batch\n",
    "            index = index.cuda(non_blocking=True)\n",
    "            img = img.cuda(non_blocking=True)\n",
    "            labels.extend(label.clone().tolist())\n",
    "            if multiscale:\n",
    "                student_feats = multi_scale(img, student)\n",
    "                teacher_feats = multi_scale(img, teacher)\n",
    "            else:\n",
    "                student_feats = student(img).clone()\n",
    "                teacher_feats = teacher(img).clone()\n",
    "\n",
    "            # init storage feature matrix\n",
    "            if (\n",
    "                is_main_process()\n",
    "                and student_features is None\n",
    "                and teacher_features is None\n",
    "            ):\n",
    "                student_features = torch.zeros(\n",
    "                    len(loader.dataset), student_feats.shape[-1]\n",
    "                )\n",
    "                teacher_features = torch.zeros(\n",
    "                    len(loader.dataset), teacher_feats.shape[-1]\n",
    "                )\n",
    "                if use_cuda:\n",
    "                    student_features = student_features.cuda(non_blocking=True)\n",
    "                    teacher_features = teacher_features.cuda(non_blocking=True)\n",
    "\n",
    "            if distributed:\n",
    "                ngpu = dist.get_world_size()\n",
    "                y_all = torch.empty(\n",
    "                    ngpu, index.size(0), dtype=index.dtype, device=index.device\n",
    "                )\n",
    "                y_l = list(y_all.unbind(0))\n",
    "                y_all_reduce = torch.distributed.all_gather(y_l, index, async_op=True)\n",
    "                y_all_reduce.wait()\n",
    "                index_all = torch.cat(y_l)\n",
    "\n",
    "                # share features between processes\n",
    "                student_feats_all = torch.empty(\n",
    "                    ngpu,\n",
    "                    student_feats.size(0),\n",
    "                    student_feats.size(1),\n",
    "                    dtype=student_feats.dtype,\n",
    "                    device=student_feats.device,\n",
    "                )\n",
    "                teacher_feats_all = torch.empty(\n",
    "                    ngpu,\n",
    "                    teacher_feats.size(0),\n",
    "                    teacher_feats.size(1),\n",
    "                    dtype=teacher_feats.dtype,\n",
    "                    device=teacher_feats.device,\n",
    "                )\n",
    "\n",
    "                student_output_l = list(student_feats_all.unbind(0))\n",
    "                student_output_all_reduce = torch.distributed.all_gather(\n",
    "                    student_output_l, student_feats, async_op=True\n",
    "                )\n",
    "                teacher_output_l = list(teacher_feats_all.unbind(0))\n",
    "                teacher_output_all_reduce = torch.distributed.all_gather(\n",
    "                    teacher_output_l, teacher_feats, async_op=True\n",
    "                )\n",
    "\n",
    "                student_output_all_reduce.wait()\n",
    "                teacher_output_all_reduce.wait()\n",
    "\n",
    "                # update storage feature matrix\n",
    "                if is_main_process():\n",
    "                    if use_cuda:\n",
    "                        student_features.index_copy_(\n",
    "                            0, index_all, torch.cat(student_output_l)\n",
    "                        )\n",
    "                        teacher_features.index_copy_(\n",
    "                            0, index_all, torch.cat(teacher_output_l)\n",
    "                        )\n",
    "                    else:\n",
    "                        student_features.index_copy_(\n",
    "                            0, index_all.cpu(), torch.cat(student_output_l).cpu()\n",
    "                        )\n",
    "                        teacher_features.index_copy_(\n",
    "                            0, index_all.cpu(), torch.cat(teacher_output_l).cpu()\n",
    "                        )\n",
    "            else:\n",
    "                student_features[list(index), :] = student_feats\n",
    "                teacher_features[list(index), :] = teacher_feats\n",
    "\n",
    "    if is_main_process():\n",
    "        student_features = nn.functional.normalize(student_features, dim=1, p=2)\n",
    "        teacher_features = nn.functional.normalize(teacher_features, dim=1, p=2)\n",
    "\n",
    "    features = {\"student\": student_features, \"teacher\": teacher_features}\n",
    "    labels = torch.tensor(labels).long()\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62ed267-608c-4eac-b46e-a5b1fd559435",
   "metadata": {},
   "source": [
    "pretrain utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf13ae8-b14f-4e2c-9dcc-7d32c3263fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    student,\n",
    "    teacher,\n",
    "    teacher_without_ddp,\n",
    "    dino_loss,\n",
    "    data_loader,\n",
    "    optimizer,\n",
    "    lr_schedule,\n",
    "    wd_schedule,\n",
    "    momentum_schedule,\n",
    "    epoch,\n",
    "    nepochs,\n",
    "    fp16_scaler,\n",
    "    clip_grad,\n",
    "    freeze_last_layer,\n",
    "    gpu_id,\n",
    "):\n",
    "    metric_logger = MetricLogger(delimiter=\"  \")\n",
    "    with tqdm(\n",
    "        data_loader,\n",
    "        desc=(f\"Epoch [{epoch+1}/{nepochs}]\"),\n",
    "        unit=\" img\",\n",
    "        ncols=80,\n",
    "        unit_scale=data_loader.batch_size,\n",
    "        leave=False,\n",
    "        disable=not (gpu_id in [-1, 0]),\n",
    "    ) as t:\n",
    "        for it, (images, _) in enumerate(t):\n",
    "            # update weight decay and learning rate according to their schedule\n",
    "            it = len(data_loader) * epoch + it  # global training iteration\n",
    "            for i, param_group in enumerate(optimizer.param_groups):\n",
    "                param_group[\"lr\"] = lr_schedule[it]\n",
    "                if i == 0:  # only the first group is regularized\n",
    "                    param_group[\"weight_decay\"] = wd_schedule[it]\n",
    "\n",
    "            # move images to gpu\n",
    "            if gpu_id == -1:\n",
    "                images = [im.cuda(non_blocking=True) for im in images]\n",
    "            else:\n",
    "                device = torch.device(f\"cuda:{gpu_id}\")\n",
    "                images = [im.to(device, non_blocking=True) for im in images]\n",
    "            # teacher and student forward passes + compute dino loss\n",
    "            with torch.cuda.amp.autocast(fp16_scaler is not None):\n",
    "                teacher_output = teacher(\n",
    "                    images[:2]\n",
    "                )  # only the 2 global views pass through the teacher\n",
    "                student_output = student(images)\n",
    "                loss = dino_loss(student_output, teacher_output, epoch)\n",
    "\n",
    "            if not math.isfinite(loss.item()):\n",
    "                tqdm.write(\n",
    "                    \"Loss is {}, stopping training\".format(loss.item()), force=True\n",
    "                )\n",
    "                sys.exit(1)\n",
    "\n",
    "            # student update\n",
    "            optimizer.zero_grad()\n",
    "            param_norms = None\n",
    "            if fp16_scaler is None:\n",
    "                loss.backward()\n",
    "                if clip_grad:\n",
    "                    param_norms = clip_gradients(student, clip_grad)\n",
    "                cancel_gradients_last_layer(epoch, student, freeze_last_layer)\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                fp16_scaler.scale(loss).backward()\n",
    "                if clip_grad:\n",
    "                    fp16_scaler.unscale_(\n",
    "                        optimizer\n",
    "                    )  # unscale the gradients of optimizer's assigned params in-place\n",
    "                    param_norms = clip_gradients(student, clip_grad)\n",
    "                cancel_gradients_last_layer(epoch, student, freeze_last_layer)\n",
    "                fp16_scaler.step(optimizer)\n",
    "                fp16_scaler.update()\n",
    "\n",
    "            # EMA update for the teacher\n",
    "            with torch.no_grad():\n",
    "                m = momentum_schedule[it]  # momentum parameter\n",
    "                if torch.cuda.device_count() > 1:\n",
    "                    student_params = student.module.parameters()\n",
    "                else:\n",
    "                    student_params = student.parameters()\n",
    "                for param_q, param_k in zip(\n",
    "                    student_params, teacher_without_ddp.parameters()\n",
    "                ):\n",
    "                    param_k.data.mul_(m).add_((1 - m) * param_q.detach().data)\n",
    "\n",
    "            # logging\n",
    "            torch.cuda.synchronize()\n",
    "            metric_logger.update(loss=loss.item())\n",
    "            metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
    "            metric_logger.update(wd=optimizer.param_groups[0][\"weight_decay\"])\n",
    "\n",
    "    # gather the stats from all processes\n",
    "    metric_logger.synchronize_between_processes(gpu_id)\n",
    "    # print(\"Averaged stats:\", metric_logger)\n",
    "    train_stats = {k: meter.global_avg for k, meter in metric_logger.meters.items()}\n",
    "    return train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9174f341-24cd-4101-b6dc-7088b006b99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_one_epoch(\n",
    "    epoch,\n",
    "    student: nn.Module,\n",
    "    teacher: nn.Module,\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    "    features_dir: Path,\n",
    "    arch: str,\n",
    "    patch_size: int,\n",
    "    drop_path_rate: float,\n",
    "    k: int,\n",
    "    temperature: float,\n",
    "    distributed: bool,\n",
    "    save_features: bool = False,\n",
    "    use_cuda: bool = False,\n",
    "):\n",
    "    student_model = vits.__dict__[arch](\n",
    "        patch_size=patch_size, drop_path_rate=drop_path_rate, num_classes=0\n",
    "    )\n",
    "    teacher_model = vits.__dict__[arch](patch_size=patch_size, num_classes=0)\n",
    "    tqdm.write(f\"Teacher & student models {arch} {patch_size}x{patch_size} built.\")\n",
    "    student_model.cuda()\n",
    "    teacher_model.cuda()\n",
    "    tqdm.write(f\"Loading epoch {epoch} weights...\")\n",
    "    student_weights = student.state_dict()\n",
    "    teacher_weights = teacher.state_dict()\n",
    "    load_weights(student_model, student_weights)\n",
    "    load_weights(teacher_model, teacher_weights)\n",
    "    student_model.eval()\n",
    "    teacher_model.eval()\n",
    "\n",
    "    # ============ extract student features ============\n",
    "    tqdm.write(\"Extracting features for query set...\")\n",
    "    train_features, train_labels = extract_multiple_features(\n",
    "        student_model, teacher_model, train_dataloader, distributed, use_cuda\n",
    "    )\n",
    "    tqdm.write(\"Extracting features for test set...\")\n",
    "    test_features, test_labels = extract_multiple_features(\n",
    "        student_model, teacher_model, test_dataloader, distributed, use_cuda\n",
    "    )\n",
    "\n",
    "    teacher_train_features, teacher_test_features = (\n",
    "        train_features[\"teacher\"],\n",
    "        test_features[\"teacher\"],\n",
    "    )\n",
    "    student_train_features, student_test_features = (\n",
    "        train_features[\"student\"],\n",
    "        test_features[\"student\"],\n",
    "    )\n",
    "\n",
    "    # save features and labels\n",
    "    if save_features and is_main_process():\n",
    "        for name, feats in train_features.items():\n",
    "            torch.save(feats.cpu(), Path(features_dir, f\"{name}_train_feat.pth\"))\n",
    "        for name, feats in train_features.items():\n",
    "            torch.save(feats.cpu(), Path(features_dir, f\"{name}_test_feat.pth\"))\n",
    "        torch.save(train_labels.cpu(), Path(features_dir, \"train_labels.pth\"))\n",
    "        torch.save(test_labels.cpu(), Path(features_dir, \"test_labels.pth\"))\n",
    "\n",
    "    results = defaultdict(dict)\n",
    "    if is_main_process():\n",
    "        assert len(torch.unique(train_labels)) == len(\n",
    "            torch.unique(test_labels)\n",
    "        ), \"train & test dataset have different number of classes!\"\n",
    "        num_classes = len(torch.unique(train_labels))\n",
    "        if use_cuda:\n",
    "            teacher_train_features, teacher_test_features = (\n",
    "                teacher_train_features.cuda(),\n",
    "                teacher_test_features.cuda(),\n",
    "            )\n",
    "            student_train_features, student_test_features = (\n",
    "                student_train_features.cuda(),\n",
    "                student_test_features.cuda(),\n",
    "            )\n",
    "            train_labels, test_labels = train_labels.cuda(), test_labels.cuda()\n",
    "\n",
    "        tqdm.write(\"Features are ready!\\nStarting kNN classification.\")\n",
    "        teacher_acc, teacher_auc = knn_classifier(\n",
    "            teacher_train_features,\n",
    "            train_labels,\n",
    "            teacher_test_features,\n",
    "            test_labels,\n",
    "            k,\n",
    "            temperature,\n",
    "            num_classes,\n",
    "        )\n",
    "        student_acc, student_auc = knn_classifier(\n",
    "            student_train_features,\n",
    "            train_labels,\n",
    "            student_test_features,\n",
    "            test_labels,\n",
    "            k,\n",
    "            temperature,\n",
    "            num_classes,\n",
    "        )\n",
    "        results[\"teacher\"].update({\"acc\": teacher_acc, \"auc\": teacher_auc})\n",
    "        results[\"student\"].update({\"acc\": student_acc, \"auc\": student_auc})\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25c678a-3ebe-4e4e-a1a9-a0ed9494d5d2",
   "metadata": {},
   "source": [
    "pretrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d19b46e-3c35-4c37-98ff-5f39a7cba18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_run = 0\n",
    "stop = False\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for epoch in range(epochs_run, cfg.training.nepochs):\n",
    "    epoch_start_time = time.time()\n",
    "    if cfg.wandb.enable and is_main_process():\n",
    "        log_dict = {\"epoch\": epoch}\n",
    "\n",
    "    if distributed:\n",
    "        data_loader.sampler.set_epoch(epoch)\n",
    "\n",
    "    # training one epoch of DINO\n",
    "    train_stats = train_one_epoch(\n",
    "        student,\n",
    "        teacher,\n",
    "        teacher_without_ddp,\n",
    "        dino_loss,\n",
    "        data_loader,\n",
    "        optimizer,\n",
    "        lr_schedule,\n",
    "        wd_schedule,\n",
    "        momentum_schedule,\n",
    "        epoch,\n",
    "        cfg.training.nepochs,\n",
    "        fp16_scaler,\n",
    "        cfg.training.clip_grad,\n",
    "        cfg.training.freeze_last_layer,\n",
    "        gpu_id,\n",
    "    )\n",
    "\n",
    "    if cfg.wandb.enable and is_main_process():\n",
    "        update_log_dict(\"train\", train_stats, log_dict, step=\"epoch\")\n",
    "\n",
    "    if is_main_process():\n",
    "        snapshot = {\n",
    "            \"epoch\": epoch,\n",
    "            \"student\": student.state_dict(),\n",
    "            \"teacher\": teacher.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"dino_loss\": dino_loss.state_dict(),\n",
    "        }\n",
    "        if fp16_scaler is not None:\n",
    "            snapshot[\"fp16_scaler\"] = fp16_scaler.state_dict()\n",
    "\n",
    "    # only run tuning on rank 0, otherwise one has to take care of gathering knn metrics from multiple gpus\n",
    "    tune_results = None\n",
    "    if (\n",
    "        cfg.early_stopping.tune_every\n",
    "        and epoch % cfg.early_stopping.tune_every == 0\n",
    "        and is_main_process()\n",
    "    ):\n",
    "        tune_results = tune_one_epoch(\n",
    "            epoch + 1,\n",
    "            student,\n",
    "            teacher_without_ddp,\n",
    "            downstream_train_loader,\n",
    "            downstream_test_loader,\n",
    "            features_dir,\n",
    "            cfg.model.arch,\n",
    "            cfg.model.patch_size,\n",
    "            cfg.model.drop_path_rate,\n",
    "            cfg.early_stopping.knn.k,\n",
    "            cfg.early_stopping.knn.temperature,\n",
    "            False,\n",
    "            cfg.early_stopping.knn.save_features,\n",
    "            cfg.early_stopping.knn.use_cuda,\n",
    "        )\n",
    "\n",
    "        if cfg.wandb.enable and is_main_process():\n",
    "            update_log_dict(\"tune\", tune_results, log_dict, step=\"epoch\")\n",
    "\n",
    "    if is_main_process():\n",
    "        early_stopping(epoch, tune_results, snapshot)\n",
    "        if early_stopping.early_stop and cfg.early_stopping.enable:\n",
    "            stop = True\n",
    "\n",
    "    if stop:\n",
    "        tqdm.write(\n",
    "            f\"Stopping early because best {cfg.early_stopping.tracking} was reached {cfg.early_stopping.patience} epochs ago\"\n",
    "        )\n",
    "        break\n",
    "\n",
    "    # save snapshot and log to wandb\n",
    "    if is_main_process():\n",
    "        save_path = Path(snapshot_dir, f\"epoch_{epoch:03}.pt\")\n",
    "        if (\n",
    "            cfg.early_stopping.save_every\n",
    "            and epoch % cfg.early_stopping.save_every == 0\n",
    "            and not save_path.is_file()\n",
    "        ):\n",
    "            torch.save(snapshot, save_path)\n",
    "\n",
    "        if cfg.wandb.enable:\n",
    "            wandb.log(log_dict, step=epoch)\n",
    "\n",
    "    log_stats = {\n",
    "        **{f\"train_{k}\": v for k, v in train_stats.items()},\n",
    "        \"epoch\": epoch,\n",
    "    }\n",
    "    if is_main_process():\n",
    "        with open(Path(output_dir, \"log.txt\"), \"a\") as f:\n",
    "            f.write(json.dumps(log_stats) + \"\\n\")\n",
    "\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_mins, epoch_secs = compute_time(epoch_start_time, epoch_end_time)\n",
    "    if is_main_process():\n",
    "        tqdm.write(\n",
    "            f\"End of epoch {epoch+1}/{cfg.training.nepochs} \\t Time Taken:  {epoch_mins}m {epoch_secs}s\"\n",
    "        )\n",
    "\n",
    "    # ensure other gpus wait until gpu_0 is finished with tuning before starting next training iteration\n",
    "    if distributed:\n",
    "        torch.distributed.barrier()\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "print(\"Pretraining time {}\".format(total_time_str))\n",
    "\n",
    "if distributed:\n",
    "    torch.distributed.destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ecebd5-53d7-4984-bed6-9508a74d4e12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
